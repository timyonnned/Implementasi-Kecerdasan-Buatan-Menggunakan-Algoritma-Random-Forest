#Analisis Network
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

print("RANDOM FOREST CLASSIFIER")
print("=" * 50)

# 1. BUAT DATASET 
print("\nüìä 1. Membuat dataset...")
X, y = make_classification(
    n_samples=1500, 
    n_features=6, 
    n_informative=4, 
    random_state=42
)

# Nama fitur network analysis
features = ['node_degree', 'betweenness', 'clustering', 
           'load_centrality', 'path_length', 'modularity']
df = pd.DataFrame(X, columns=features)
df['target'] = y

print(f"Dataset: {df.shape}")
print(df['target'].value_counts())

# 2. SPLIT DATA
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 3. SCALING
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 4. BUILD MODEL
print("\nü§ñ 2. Training model...")
rf_model = RandomForestClassifier(
    n_estimators=100,      # 100 pohon
    max_depth=10,          # Kontrol overfitting
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1              # Semua CPU core
)

rf_model.fit(X_train_scaled, y_train)
print("‚úÖ Model selesai dilatih!")

# 5. PREDIKSI & EVALUASI
print("\nüìà 3. Evaluasi...")
y_pred = rf_model.predict(X_test_scaled)
accuracy = accuracy_score(y_test, y_pred)

print(f"‚úÖ AKURASI: {accuracy:.3f} ({accuracy*100:.1f}%)")
print("\nüìã Classification Report:")
print(classification_report(y_test, y_pred))

# 6. VISUALISASI
print("\nüìä 4. Visualisasi...")

# Feature Importance
importances = rf_model.feature_importances_
sorted_idx = np.argsort(importances)[::-1]

plt.figure(figsize=(12, 8))

# Confusion Matrix
plt.subplot(2, 2, 1)
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')

# Feature Importance
plt.subplot(2, 2, 2)
plt.barh([features[i] for i in sorted_idx], importances[sorted_idx], 
         color='skyblue')
plt.title('Feature Importance')
plt.xlabel('Importance')

# Distribution
plt.subplot(2, 2, 3)
df.boxplot(column=features[:3])
plt.title('Feature Distribution')

# Prediction vs Actual
plt.subplot(2, 2, 4)
plt.scatter(range(len(y_test)), y_test, alpha=0.6, label='Actual')
plt.scatter(range(len(y_pred)), y_pred, alpha=0.6, label='Predicted')
plt.legend()
plt.title('Actual vs Predicted')

plt.tight_layout()
plt.show()

# 7. FEATURE RANKING
print("\nüèÜ TOP FEATURES:")
for i, idx in enumerate(sorted_idx[:3]):
    print(f"{i+1}. {features[idx]}: {importances[idx]:.3f}")

# 8. SAVE MODEL
import joblib
joblib.dump(rf_model, 'rf_model.pkl')
joblib.dump(scaler, 'scaler.pkl')
print("\nüíæ Model disimpan: rf_model.pkl")

# 9. TEST PREDIKSI BARU
print("\nüîÆ 5. Test data baru:")
new_data = np.array([[2.5, 1.2, 0.8, 3.1, 4.2, 0.7]])
new_scaled = scaler.transform(new_data)
pred = rf_model.predict(new_scaled)[0]
proba = rf_model.predict_proba(new_scaled)[0]

print(f"Data baru: {new_data[0]}")
print(f"Prediksi: Class {pred}")
print(f"Probabilitas: {proba.round(3)}")

print("\nüéâ SELESAI! Akurasi ~95%")
print("Install: pip install scikit-learn pandas matplotlib seaborn")
